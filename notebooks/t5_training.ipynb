{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/semantic-systems/t5-information-retrieval.git"
      ],
      "metadata": {
        "id": "zmu_oa7XCBNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Switch path to working dir\n",
        "%cd t5-information-retrieval/question_generation-master/"
      ],
      "metadata": {
        "id": "sBIe9ItvhTfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install deps\n"
      ],
      "metadata": {
        "id": "IwYdTX5vgcWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m nltk.downloader punkt"
      ],
      "metadata": {
        "id": "iD87SIaE_3N0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "Lwt9FWV6ggGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train data\n"
      ],
      "metadata": {
        "id": "tjG--zXSe-yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BEFORE TRAINING: Determine the max_source_length and max_target_length and adjust accordingly in the call below\n",
        "# Maybe see if adding </s> manually causes problems\n",
        "# Prepare the data for training\n",
        "!python prepare_data.py --task qa --model_type t5 --dataset_path data/enron_train --qg_format highlight_qg_format --max_source_length 3865 --max_target_length 1534 --train_file_name enron_train_data_qg_hl_t5.pt --valid_file_name enron_valid_data_qg_hl_t5.pt"
      ],
      "metadata": {
        "id": "ze0lT-qegQky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "# original epoch num was 5\n",
        "# model type can be t5 or flan-t5\n",
        "\n",
        "from run_qg import run_qg\n",
        "import time\n",
        "\n",
        "args_dict = {\n",
        "    \"model_name_or_path\": \"google/flan-t5-small\",\n",
        "    \"model_type\": \"t5\",\n",
        "    \"tokenizer_name_or_path\": \"t5_qg_tokenizer\",\n",
        "    \"output_dir\": \"flan-small\",\n",
        "    \"train_file_path\": \"data/enron_train_data_qg_hl_t5.pt\",\n",
        "    \"valid_file_path\": \"data/enron_valid_data_qg_hl_t5.pt\",\n",
        "    \"per_device_train_batch_size\": 1,\n",
        "    \"per_device_eval_batch_size\": 1,\n",
        "    \"gradient_accumulation_steps\": 8,\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"num_train_epochs\": 5,\n",
        "    \"seed\": 777,\n",
        "    \"do_train\": True,\n",
        "    \"do_eval\": False,\n",
        "    \"logging_steps\": 100,\n",
        "    \"prediction_loss_only\": True\n",
        "}\n",
        "\n",
        "start = time.time()\n",
        "run_qg(args_dict)\n",
        "end = time.time()\n",
        "print(\"finished execution, total time elapsed in seconds:\", end - start)\n"
      ],
      "metadata": {
        "id": "9xY4iG03gXBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zip up the model\n",
        "!zip -r ./flan-t5-small-trained.zip ./flan-t5-small-trained"
      ],
      "metadata": {
        "id": "u4JgjKsHdnbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import shutil"
      ],
      "metadata": {
        "id": "m_za-U0Lnhgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy(\"./flan-t5-small-trained.zip\", \"/path/to/save/location\")"
      ],
      "metadata": {
        "id": "F_PkjHL1ntu1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}